{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GraphDiffToTransformation",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1y7MqTE_mKI74KRtiNhppSpAj3fychEUF",
      "authorship_tag": "ABX9TyOH16f1U6Sh2tm0+UQ+1xCc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c0e917bd38874d91b63120c6a6b99563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_247a461e92aa49f4821d202e7083c056",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c58342dd717643e4a994b91ce6889861",
              "IPY_MODEL_a50ed4333d884934996f14975af23484",
              "IPY_MODEL_c30df628402b436a932c93740a15abf7"
            ]
          }
        },
        "247a461e92aa49f4821d202e7083c056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c58342dd717643e4a994b91ce6889861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a6de68b759d14d2cba0c4793efdde57e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  2%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_858eb4bd87a24aa4bb34110323a9831a"
          }
        },
        "a50ed4333d884934996f14975af23484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d2cdc6e3f71b43b68aa497df2cc2a355",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 75000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1528,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b8ec5b302034a98862007479d4b3a43"
          }
        },
        "c30df628402b436a932c93740a15abf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_286ba5984e3d4711920bfa7dd90476a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1528/75000 [36:58&lt;28:49:10,  1.41s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a0c40f933924807bcb0ecbcdaeb4666"
          }
        },
        "a6de68b759d14d2cba0c4793efdde57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "858eb4bd87a24aa4bb34110323a9831a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2cdc6e3f71b43b68aa497df2cc2a355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b8ec5b302034a98862007479d4b3a43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "286ba5984e3d4711920bfa7dd90476a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a0c40f933924807bcb0ecbcdaeb4666": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabh1mohite/TDVR/blob/main/GraphDiffToTransformation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gZQpKJMw3UX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fdad3a8-aa8f-41c4-c6a9-cede7e9c7299"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7FUfp-aw5iA"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jm0GxuxxGW_"
      },
      "source": [
        "# # Turn a Unicode string to plain ASCII, thanks to\n",
        "# # https://stackoverflow.com/a/518232/2809427\n",
        "# def unicodeToAscii(s):\n",
        "#     return ''.join(\n",
        "#         c for c in unicodedata.normalize('NFD', s)\n",
        "#         if unicodedata.category(c) != 'Mn'\n",
        "#     )\n",
        "\n",
        "# # Lowercase, trim, and remove non-letter characters"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Snq3OIeCxISc"
      },
      "source": [
        "def readLangs(lang1, lang2, lang3, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('/content/drive/MyDrive/NLP/Trance/CSV/dataset.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[s for s in l.split(',')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang_1 = Lang(lang2)\n",
        "        input_lang_2 = Lang(lang1)\n",
        "        output_lang = Lang(lang3)\n",
        "    else:\n",
        "        input_lang_1 = Lang(lang1)\n",
        "        input_lang_2 = Lang(lang2)\n",
        "        output_lang = Lang(lang3)\n",
        "    return input_lang_1, input_lang_2, output_lang, pairs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caQt35KAxc9L",
        "outputId": "1992fa9f-8084-4fc7-d395-7331510c74ab"
      },
      "source": [
        "def prepareData(lang1, lang2, lang3, reverse=False):\n",
        "    input_lang_1, input_lang_2, output_lang, pairs = readLangs(lang1, lang2, lang3, reverse)\n",
        "    print(lang1)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    # pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    # ctr = 0\n",
        "    for pair in pairs:\n",
        "        # print('pair - ', pair)\n",
        "        # ctr += 1\n",
        "        # if ctr > 10:\n",
        "        #     break\n",
        "        input_lang_1.addSentence(pair[0])\n",
        "        input_lang_1.addSentence(pair[1])\n",
        "        # input_lang_1.addSentence(pair[2])\n",
        "        \n",
        "        input_lang_2.addSentence(pair[1])\n",
        "        # input_lang_2.addSentence(pair[2])\n",
        "        input_lang_2.addSentence(pair[0])\n",
        "\n",
        "        output_lang.addSentence(pair[2])\n",
        "        # output_lang.addSentence(pair[1])\n",
        "        # output_lang.addSentence(pair[0])\n",
        "        \n",
        "        # for word in pair[0].split(' '):\n",
        "        #     input_lang_1.addWord(word)\n",
        "        # for word in pair[1].split(' '):\n",
        "        #     input_lang_2.addWord(word)\n",
        "        # for word in pair[2].split(' '):\n",
        "        #     output_lang.addWord(word)\n",
        "\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang_1.name, input_lang_1.n_words)\n",
        "    print(input_lang_2.name, input_lang_2.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang_1, input_lang_2, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang_1, input_lang_2, output_lang, pairs = prepareData('init', 'final', 'transformation', True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "init\n",
            "Read 31800 sentence pairs\n",
            "Trimmed to 31800 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "final 256194\n",
            "init 256194\n",
            "transformation 45\n",
            "['4 3 5 4 2 4 2 4 4 5 4 1 2 1 4 1 3 4 4 2 4 4 4 4 1 c8200661feb7927861f5a7f5f6b51e1d 1e736e30f50dfe42581bdf1c20181487 44502c72f4d0fa22832333a7efa43831 dc179b89ab1d21903def8758075b43ed 0b053511e0180e19cb9f472b1726fb0b fa375423bafd7b48b3e177c660d880e9 0b053511e0180e19cb9f472b1726fb0b dc179b89ab1d21903def8758075b43ed 4f955ef8fbb714f52e749d537ea2ff53 44502c72f4d0fa22832333a7efa43831 385099f1ea1f119e20af2765e0bd6ed2 34b8a5e9772cd73daba26c68a209127f 0b053511e0180e19cb9f472b1726fb0b 34b8a5e9772cd73daba26c68a209127f 38a8cf581986627f062b87819e90938f 34b8a5e9772cd73daba26c68a209127f 1e736e30f50dfe42581bdf1c20181487 dc179b89ab1d21903def8758075b43ed 4f955ef8fbb714f52e749d537ea2ff53 0b053511e0180e19cb9f472b1726fb0b 090a3276bf357cc2ba00aec70bef1c8f ee744c0b6a7285536ec2e8f3364d5d60 89af402e42075dcd347caa4f937e31b7 38a8cf581986627f062b87819e90938f 34b8a5e9772cd73daba26c68a209127f e400a926239a77be434218ce4c5acba2 09e0c5f6c26d78c61d24e9ed8386a91a 5c051d19c0e3e308c9558c2548e3ed54 e2d38e67601e0db62e4a7d8b740d92cd 464d3ce37ca7acd4c94b090a31486223 a61c694a3e2139f53e11feb577b9e3f1 4385c20bf8dcc5348ad7ff10710749d1 3cd79db75a0c61984a828acda5fc43f2 cba182a05dcc68f50329fce4daddbcd7 ec077c1cec644648a44b93abad31a53f 6b9f35b390c9a62e1ae319dad1c20408 2c84fd8146c638e4d269745b0e8a2c23 4e79690d41cd932d41a1a72f8754c992 2c84fd8146c638e4d269745b0e8a2c23 26bbb4552413b2d26862563cf89ce7a6 27ef3b7d79fcd676065670f21b09e65d f5c0acec4fccb14895c23a08ee32c87a 91af760d54156e5b8602bcbdbfb6bb3f cba182a05dcc68f50329fce4daddbcd7 f7627d16459401035ba7f96f412338b9 3c26be2f6a0bf71c550e7621eecc3637 e5e32aa00803d1b43825f281d128b2f9 3ff6f05dd0fce12e3fe965a36251e50e 26bbb4552413b2d26862563cf89ce7a6 27ef3b7d79fcd676065670f21b09e65d', '5 1 5 4 2 1 5 2 4 1 5 5 1 6 1 2 1 1 5 1 3 4 1 5 2 1 5 2 1 5 1 5 1 5 1 1 1 a508b8e8dddfd834a6b5d0babcd3d2cc 2cb17e69baebaeed67190ad729bb2601 b03cce669c6980f7ce1d46da69c9bb2f da596c60d37e8a0dce8fa70ee4867c3a 036ba2f95c52c2395335611e9aff9766 2cb17e69baebaeed67190ad729bb2601 e6ea46ed99fcd234cd8ed1cbb32ef8aa 036ba2f95c52c2395335611e9aff9766 e2166250e283a08b7aed67a9490e993d 2cb17e69baebaeed67190ad729bb2601 443ec327fc8a29034e4e9f112393bb72 b03cce669c6980f7ce1d46da69c9bb2f 2cb17e69baebaeed67190ad729bb2601 b237480bf7a5df55e28c572d059dfade 291dd475d0224126a68550d7c406f3b1 ae41c6e0c09dccc0a7d0fa84b0fd6a9d 291dd475d0224126a68550d7c406f3b1 291dd475d0224126a68550d7c406f3b1 bcc9a6a54f77cc6d99139e3afce76c4d 2cb17e69baebaeed67190ad729bb2601 77e4d37e7ba5fecb1e1d6c96398f216d da596c60d37e8a0dce8fa70ee4867c3a 2cb17e69baebaeed67190ad729bb2601 443ec327fc8a29034e4e9f112393bb72 036ba2f95c52c2395335611e9aff9766 2cb17e69baebaeed67190ad729bb2601 443ec327fc8a29034e4e9f112393bb72 036ba2f95c52c2395335611e9aff9766 2cb17e69baebaeed67190ad729bb2601 abf5fd1a335fc162c9cad6d5e11cd489 2cb17e69baebaeed67190ad729bb2601 fa7187242c77ca5242bdbfd874d3bbf3 2cb17e69baebaeed67190ad729bb2601 bcc9a6a54f77cc6d99139e3afce76c4d 2cb17e69baebaeed67190ad729bb2601 2cb17e69baebaeed67190ad729bb2601 291dd475d0224126a68550d7c406f3b1 50ed17de297655f59b4ec3459e949267 636aafc65ade57ab2cd4781f59b32add 038cc1e81882d978c2962c22a8427e01 cb714208f86a261a16cef03ae2442610 15080f0804684de900c9361be84c8cd2 636aafc65ade57ab2cd4781f59b32add 9f2f0f702f46689e63cce9a70ae9a48a 27d867f49c9aac1d4a00867ee30b54ff f0f2d9982d1ffc6eece4031816345d0f 041052ff5895271710d8582119fce154 71190d98aa953e1e85163234fc3cf050 78aef7983b5c0f53f32feb010a7b696a af8fa1510ec077e6adfac507d707d38c 8d5a112493cf76401708c4d6b1322f82 357d483bbe8b36d5177e9eabed34c42b 792933d236039ce915a3c808adaccbd9 357d483bbe8b36d5177e9eabed34c42b 357d483bbe8b36d5177e9eabed34c42b 9648f2bbb86a066da3192971f3da6f53 732ae55cd42dd499e45b9e163095b253 b88f5fb369a24cdb021e00fa12b8333e 45293318b46b4921fca8289251a14524 732ae55cd42dd499e45b9e163095b253 71190d98aa953e1e85163234fc3cf050 8d1d24da22eda7ef7e88c09b7254f27d af8fa1510ec077e6adfac507d707d38c 251b611cd22769b5be2811d069ecd024 f213580c3a0119980331e6f1a38145e7 af8fa1510ec077e6adfac507d707d38c a8b2a9086c1ce06d6c17f5be6f8e732a ec69f99dbe638a91a1293649fa98fc72 5fe97cc99b67b05d0db73dffc6c023f0 53a1eaf62eee9e71983fa99f7b4fee97 9648f2bbb86a066da3192971f3da6f53 732ae55cd42dd499e45b9e163095b253 732ae55cd42dd499e45b9e163095b253 357d483bbe8b36d5177e9eabed34c42b', 'change color of 0 to purple move 3 towards behind-right by 1 steps ', '2 1 1 2 1 1 a6471b147e51f4d317e48cc16ab908ed ab35e84a215f0f711ed629c2abb9efa0 ab35e84a215f0f711ed629c2abb9efa0 a6471b147e51f4d317e48cc16ab908ed ab35e84a215f0f711ed629c2abb9efa0 ab35e84a215f0f711ed629c2abb9efa0 03ee50de8f77d3380dd5c8954e3ea594 379e2a0e1ed586cc8e3d849ce2f661bc 379e2a0e1ed586cc8e3d849ce2f661bc 03ee50de8f77d3380dd5c8954e3ea594 379e2a0e1ed586cc8e3d849ce2f661bc 379e2a0e1ed586cc8e3d849ce2f661bc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_hPMAnTx8xi"
      },
      "source": [
        "class EncoderRNNL1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNNL1, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8X1fB-e0o8R"
      },
      "source": [
        "class EncoderRNNL2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNNL2, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bjl97o-0snI"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxZeZCgL0ujb"
      },
      "source": [
        "MAX_LENGTH = 128\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUodhjtR0yJD"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor_1 = tensorFromSentence(input_lang_1, pair[0])\n",
        "    input_tensor_2 = tensorFromSentence(input_lang_2, pair[1])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[2])\n",
        "    return (input_tensor_1, input_tensor_2, target_tensor)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw0veHNx025J"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor_1, input_tensor_2, target_tensor, encoder_1, encoder_2, decoder, encoder_optimizer_1, encoder_optimizer_2, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden_1 = encoder_1.initHidden()\n",
        "    encoder_hidden_2 = encoder_2.initHidden()\n",
        "\n",
        "    encoder_optimizer_1.zero_grad()\n",
        "    encoder_optimizer_2 .zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length_1 = input_tensor_1.size(0)\n",
        "    input_length_2 = input_tensor_2.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs_1 = torch.zeros(max_length, encoder_1.hidden_size, device=device)\n",
        "    encoder_outputs_2 = torch.zeros(max_length, encoder_2.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "################\n",
        "    input_tensor_1 = input_tensor_1.to(device)\n",
        "    input_tensor_2 = input_tensor_2.to(device)\n",
        "##############\n",
        "    for ei in range(input_length_1):\n",
        "        encoder_output_1, encoder_hidden_1 = encoder_1(input_tensor_1[ei], encoder_hidden_1)\n",
        "        encoder_outputs_1[ei] = encoder_output_1[0, 0]\n",
        "    for ei in range(input_length_2):\n",
        "        encoder_output_2, encoder_hidden_2 = encoder_2(input_tensor_2[ei], encoder_hidden_2)\n",
        "        encoder_outputs_2[ei] = encoder_output_2[0, 0]\n",
        "    encoder_outputs = encoder_outputs_1 - encoder_outputs_2\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "# marker\n",
        "    decoder_hidden = encoder_hidden_1 - encoder_hidden_2\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer_1.step()\n",
        "    encoder_optimizer_2.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG6_mCac40ds"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFNSl4AQ1mxS"
      },
      "source": [
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "def trainIters(encoder_1, encoder_2, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer_1 = optim.SGD(encoder_1.parameters(), lr=learning_rate)\n",
        "    encoder_optimizer_2 = optim.SGD(encoder_2.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "    for iter in tqdm(range(1, n_iters + 1)):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor_1 = training_pair[0]\n",
        "        input_tensor_2 = training_pair[1]\n",
        "        target_tensor = training_pair[2]\n",
        "\n",
        "        loss = train(input_tensor_1, input_tensor_2, target_tensor, encoder_1, encoder_2,\n",
        "                     decoder, encoder_optimizer_1, encoder_optimizer_2, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "        \n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "            torch.save(encoder_1.state_dict(), '/content/drive/MyDrive/NLP/Trance/models/encoder_weights_1')\n",
        "            torch.save(encoder_2.state_dict(), '/content/drive/MyDrive/NLP/Trance/models/encoder_weights_2')\n",
        "            torch.save(decoder.state_dict(), '/content/drive/MyDrive/NLP/Trance/models/decoder_weights')\n",
        "            torch.save(encoder_optimizer_1.state_dict(), '/content/drive/MyDrive/NLP/Trance/models/encoder_optimizer_1')\n",
        "            torch.save(encoder_optimizer_2.state_dict(), '/content/drive/MyDrive/NLP/Trance/models/encoder_optimizer_2')\n",
        "            torch.save(decoder_optimizer.state_dict(), '/content/drive/MyDrive/NLP/Trance/models/decoder_optimizer')\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmvFNamQ4jCv"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310,
          "referenced_widgets": [
            "c0e917bd38874d91b63120c6a6b99563",
            "247a461e92aa49f4821d202e7083c056",
            "c58342dd717643e4a994b91ce6889861",
            "a50ed4333d884934996f14975af23484",
            "c30df628402b436a932c93740a15abf7",
            "a6de68b759d14d2cba0c4793efdde57e",
            "858eb4bd87a24aa4bb34110323a9831a",
            "d2cdc6e3f71b43b68aa497df2cc2a355",
            "3b8ec5b302034a98862007479d4b3a43",
            "286ba5984e3d4711920bfa7dd90476a1",
            "9a0c40f933924807bcb0ecbcdaeb4666"
          ]
        },
        "id": "3aGcgCpj42dd",
        "outputId": "bc2ef865-c561-468a-f1b9-7870c0a7fb8d"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder_1 = EncoderRNNL1(input_lang_1.n_words, hidden_size).to(device)\n",
        "encoder_2 = EncoderRNNL2(input_lang_2.n_words, hidden_size).to(device)\n",
        "attn_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder_1, encoder_2, attn_decoder, 75000, print_every=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0e917bd38874d91b63120c6a6b99563",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/75000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2m 38s (- 1975m 6s) (100 0%) 2.6793\n",
            "5m 16s (- 1971m 18s) (200 0%) 1.9432\n",
            "7m 40s (- 1912m 21s) (300 0%) 1.7593\n",
            "10m 4s (- 1879m 59s) (400 0%) 1.5596\n",
            "12m 28s (- 1859m 42s) (500 0%) 1.5777\n",
            "14m 54s (- 1847m 57s) (600 0%) 1.7863\n",
            "17m 17s (- 1835m 47s) (700 0%) 1.4989\n",
            "19m 41s (- 1827m 4s) (800 1%) 1.6151\n",
            "22m 6s (- 1820m 34s) (900 1%) 1.6562\n",
            "24m 31s (- 1814m 16s) (1000 1%) 1.6552\n",
            "26m 54s (- 1807m 24s) (1100 1%) 1.6046\n",
            "29m 19s (- 1803m 2s) (1200 1%) 1.5851\n",
            "31m 42s (- 1797m 58s) (1300 1%) 1.6392\n",
            "34m 7s (- 1794m 14s) (1400 1%) 1.6576\n",
            "36m 31s (- 1789m 55s) (1500 2%) 1.5843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkCurE8EGon2"
      },
      "source": [
        "# modl arch, performance, analyze few examples, common patterns that are failing, overcoming existing baselines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reyBMf0_NDDW"
      },
      "source": [
        "def evaluate(encoder_1, encoder_2, decoder, sentence_1, sentence_2, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor_1 = tensorFromSentence(input_lang_1, sentence_1)\n",
        "        input_tensor_2 = tensorFromSentence(input_lang_2, sentence_2)\n",
        "        input_length_1 = input_tensor_1.size()[0]\n",
        "        input_length_2 = input_tensor_2.size()[0]\n",
        "        encoder_hidden_1 = encoder_1.initHidden()\n",
        "        encoder_hidden_2 = encoder_2.initHidden()\n",
        "\n",
        "        encoder_outputs_1 = torch.zeros(max_length, encoder_1.hidden_size, device=device)\n",
        "        encoder_outputs_2 = torch.zeros(max_length, encoder_2.hidden_size, device=device)\n",
        "        \n",
        "\n",
        "        for ei in range(input_length_1):\n",
        "            encoder_output_1, encoder_hidden_1 = encoder_1(input_tensor_1[ei],\n",
        "                                                     encoder_hidden_1)\n",
        "            encoder_outputs_1[ei] += encoder_output_1[0, 0]\n",
        "            \n",
        "        for ei in range(input_length_2):\n",
        "            encoder_output_2, encoder_hidden_2 = encoder_2(input_tensor_2[ei],\n",
        "                                                     encoder_hidden_2)\n",
        "            encoder_outputs_2[ei] += encoder_output_2[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        encoder_outputs = encoder_outputs_1 - encoder_outputs_2\n",
        "        \n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU-yauaFOAkf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}